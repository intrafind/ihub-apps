# OpenAI GPT-5.x Support

## Date
2026-01-16

## Summary

This concept document describes the implementation of support for OpenAI's GPT-5.x model family, including handling the new API parameters and maintaining backward compatibility with existing GPT-4.x and earlier models.

## Problem Statement

OpenAI introduced the GPT-5.x model family with significant API changes:
1. `max_tokens` parameter is deprecated and replaced with `max_output_tokens`
2. New `reasoning.effort` parameter with values: none, low, medium, high, xhigh
3. New `text.verbosity` parameter with values: low, medium, high
4. `temperature`, `top_p`, and `logprobs` are only supported when `reasoning.effort` is set to "none"

The application needs to support these new models while maintaining backward compatibility with existing models.

## Goals

1. Support GPT-5.x models with new API parameters
2. Maintain backward compatibility with GPT-4.x and earlier models
3. Allow configuration of reasoning effort and verbosity per model
4. Detect GPT-5.x models automatically based on model ID
5. Follow the principle of minimal changes

## Implementation

### 1. Model Detection

Added `isGPT5Model()` method to the OpenAI adapter to detect GPT-5.x models:
- Matches models starting with `gpt-5` (e.g., `gpt-5`, `gpt-5.1`, `gpt-5.2`, `gpt-5.2-pro`, `gpt-5.2-codex`)
- Matches special variants: `gpt-5-mini`, `gpt-5-nano`

**Location**: `server/adapters/openai.js`

### 2. Schema Updates

Uses existing `thinking` schema (consistent with other reasoning models like Google Gemini):
- `thinking.enabled`: boolean to enable/disable reasoning
- `thinking.budget`: integer for reasoning budget
  - 0 or disabled → maps to "none" effort
  - -1 (dynamic) → maps to "medium" effort (default)
  - 1-100 → maps to "low" effort
  - 101-500 → maps to "medium" effort
  - 501-1000 → maps to "high" effort
  - 1000+ → maps to "xhigh" effort
- `thinking.thoughts`: boolean for including thoughts
  - false → maps to "medium" verbosity
  - true → maps to "high" verbosity

**Location**: `server/validators/modelConfigSchema.js`

### 3. Adapter Changes

Modified `createCompletionRequest()` in the OpenAI adapter:
- For GPT-5.x models:
  - Use `max_output_tokens` instead of `max_tokens`
  - Add `reasoning.effort` parameter
  - Add `text.verbosity` parameter
  - Only include `temperature` when `reasoning.effort` is "none"
- For legacy models:
  - Continue using `max_tokens`
  - Always include `temperature`
  - No reasoning or verbosity parameters

**Location**: `server/adapters/openai.js`

### 4. Testing

Created comprehensive tests for GPT-5.x support:
- Model detection tests (GPT-5.x vs legacy models)
- Request parameter generation tests
- Temperature handling with different reasoning efforts
- Backward compatibility tests
- Default configuration tests

**Location**: `server/tests/gpt5-support.test.js`

## Configuration Example

Example model configuration for GPT-5.2:

```json
{
  "id": "gpt-5.2",
  "modelId": "gpt-5.2",
  "name": {
    "en": "GPT-5.2",
    "de": "GPT-5.2"
  },
  "description": {
    "en": "OpenAI's most intelligent model for general and agentic tasks",
    "de": "OpenAIs intelligentestes Modell für allgemeine und agentische Aufgaben"
  },
  "url": "https://api.openai.com/v1/chat/completions",
  "provider": "openai",
  "tokenLimit": 128000,
  "supportsTools": true,
  "supportsImages": true,
  "thinking": {
    "enabled": true,
    "budget": -1,
    "thoughts": false
  }
}
```

This uses the standard `thinking` configuration, consistent with other reasoning models.

## API Changes

### GPT-5.x Request Format

```javascript
{
  "model": "gpt-5.2",
  "messages": [...],
  "max_output_tokens": 2048,
  "reasoning": {
    "effort": "high"
  },
  "text": {
    "verbosity": "low"
  }
  // temperature only included if reasoning.effort is "none"
}
```

### Legacy Model Request Format

```javascript
{
  "model": "gpt-4",
  "messages": [...],
  "max_tokens": 1024,
  "temperature": 0.7
  // No reasoning or verbosity parameters
}
```

## Backward Compatibility

- All existing model configurations continue to work without changes
- Legacy models (GPT-4.x, GPT-3.5, o1, o3) automatically use the old API format
- The `thinking` configuration is used consistently across all reasoning-capable models
- GPT-5.x models automatically map `thinking` parameters to their API requirements

## Supported Models

### GPT-5.x Models (New API)
- `gpt-5`
- `gpt-5.1`
- `gpt-5.2`
- `gpt-5.2-pro`
- `gpt-5.2-codex`
- `gpt-5.2-chat-latest`
- `gpt-5-mini`
- `gpt-5-nano`

### Legacy Models (Old API)
- `gpt-4`, `gpt-4-turbo`, `gpt-4o`, `gpt-4o-mini`
- `gpt-3.5-turbo`
- `o1-preview`, `o1-mini`
- `o3-mini`

## Reasoning Effort Levels

Based on OpenAI documentation:

- **none**: Lower-latency interactions, supports temperature/top_p/logprobs
- **low**: Minimal reasoning, faster responses
- **medium**: Balanced reasoning (default for GPT-5.2)
- **high**: More thorough reasoning
- **xhigh**: Maximum reasoning effort (GPT-5.2 only)

## Verbosity Levels

- **low**: Concise answers, minimal code commentary
- **medium**: Balanced output length (default)
- **high**: Thorough explanations, extensive documentation

## Future Considerations

1. **Response API Support**: The problem statement mentions OpenAI's new Responses API which uses different endpoints (`/v1/responses` instead of `/v1/chat/completions`). This implementation focuses on Chat Completions API compatibility. Future work could add Responses API support.

2. **Custom Tools**: GPT-5.2 supports new custom tools with freeform inputs. Could be added in a future update.

3. **Context Management**: GPT-5.2 has new context management features (compaction, passing chain-of-thought between turns). Not implemented in this initial version.

4. **Per-Request Configuration**: Currently reasoning effort and verbosity are configured at the model level. Could be made configurable per request in the future.

## Testing

Run the GPT-5.x tests:
```bash
node server/tests/gpt5-support.test.js
```

## References

- OpenAI GPT-5.2 Documentation: https://platform.openai.com/docs/guides/latest-model
- OpenAI API Reference: https://platform.openai.com/docs/api-reference
- Concept location: `concepts/openai-openapi/openapi.yaml`
